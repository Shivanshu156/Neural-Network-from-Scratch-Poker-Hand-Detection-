{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# config_file = sys.argv[1]\n",
    "config_file = 'config.txt'\n",
    "# one_hot_train = sys.argv[2]\n",
    "one_hot_train = 'one_hot_train.csv'\n",
    "# one_hot_test = sys.argv[3]\n",
    "one_hot_test = 'one_hot_test.csv'\n",
    "# Reading configure file parameters\n",
    "epoch_no = int(input('Enter the number of epochs for training\\t'))\n",
    "file = open(config_file, 'r')\n",
    "n_input = int(file.readline().split()[0])\n",
    "n_output = int(file.readline().split()[0])\n",
    "batch_size = int(file.readline().split()[0])  # batch size\n",
    "n_hidden = int(file.readline().split()[0])\n",
    "h = []\n",
    "for word in file.readline().split():\n",
    "    h.append(int(word))\n",
    "\n",
    "# print('perceptron units are ', h)\n",
    "non_linearity = file.readline().split()[0]\n",
    "lr = file.readline().split()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of epochs: 30\n",
      "n_input = 10\n",
      "n_output = 10\n",
      "batch size = 100\n",
      "number of hidden layes = 2\n",
      "activation function = sigmoid\n",
      "learning rate = fixed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'no of epochs: {epoch_no}' + '\\n'\n",
    "      f'n_input = {n_input}' + '\\n'\n",
    "      f'n_output = {n_output}' + '\\n'\n",
    "      f'batch size = {batch_size}' + '\\n'\n",
    "      f'number of hidden layes = {n_hidden}' + '\\n'\n",
    "      f'activation function = {non_linearity}' + '\\n'\n",
    "      f'learning rate = {lr}' +'\\n'\n",
    "      )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total layers are  [10, 25, 25, 10]\n"
     ]
    }
   ],
   "source": [
    "size = [n_input]\n",
    "for neurons in h:\n",
    "    size.append(neurons)\n",
    "size.append(n_output)\n",
    "print('Total layers are ', size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(one_hot_train)\n",
    "test_data = pd.read_csv(one_hot_test)\n",
    "# train_data = train_data[:1000]\n",
    "# test_data = test_data[:1000]\n",
    "x_col = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "y_col = ['10_0', '10_1', '10_2', '10_3', '10_4', '10_5', '10_6', '10_7', '10_8', '10_9']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "       0   1  2   3  4   5  6   7  8   9  10_0  10_1  10_2  10_3  10_4  10_5  \\\n0      1  10  1  11  1  13  1  12  1   1     0     0     0     0     0     0   \n1      2  11  2  13  2  10  2  12  2   1     0     0     0     0     0     0   \n2      3  12  3  11  3  13  3  10  3   1     0     0     0     0     0     0   \n3      4  10  4  11  4   1  4  13  4  12     0     0     0     0     0     0   \n4      4   1  4  13  4  12  4  11  4  10     0     0     0     0     0     0   \n...   ..  .. ..  .. ..  .. ..  .. ..  ..   ...   ...   ...   ...   ...   ...   \n25005  3   9  2   6  4  11  4  12  2   4     1     0     0     0     0     0   \n25006  4   1  4  10  3  13  3   4  1  10     0     1     0     0     0     0   \n25007  2   1  2  10  4   4  4   1  4  13     0     1     0     0     0     0   \n25008  2  12  4   3  1  10  1  12  4   9     0     1     0     0     0     0   \n25009  1   7  3  11  3   3  4   8  3   7     0     1     0     0     0     0   \n\n       10_6  10_7  10_8  10_9  \n0         0     0     0     1  \n1         0     0     0     1  \n2         0     0     0     1  \n3         0     0     0     1  \n4         0     0     0     1  \n...     ...   ...   ...   ...  \n25005     0     0     0     0  \n25006     0     0     0     0  \n25007     0     0     0     0  \n25008     0     0     0     0  \n25009     0     0     0     0  \n\n[25010 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10_0</th>\n      <th>10_1</th>\n      <th>10_2</th>\n      <th>10_3</th>\n      <th>10_4</th>\n      <th>10_5</th>\n      <th>10_6</th>\n      <th>10_7</th>\n      <th>10_8</th>\n      <th>10_9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>11</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>11</td>\n      <td>2</td>\n      <td>13</td>\n      <td>2</td>\n      <td>10</td>\n      <td>2</td>\n      <td>12</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>12</td>\n      <td>3</td>\n      <td>11</td>\n      <td>3</td>\n      <td>13</td>\n      <td>3</td>\n      <td>10</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>10</td>\n      <td>4</td>\n      <td>11</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>13</td>\n      <td>4</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>13</td>\n      <td>4</td>\n      <td>12</td>\n      <td>4</td>\n      <td>11</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25005</th>\n      <td>3</td>\n      <td>9</td>\n      <td>2</td>\n      <td>6</td>\n      <td>4</td>\n      <td>11</td>\n      <td>4</td>\n      <td>12</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25006</th>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>10</td>\n      <td>3</td>\n      <td>13</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25007</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>10</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25008</th>\n      <td>2</td>\n      <td>12</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>12</td>\n      <td>4</td>\n      <td>9</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25009</th>\n      <td>1</td>\n      <td>7</td>\n      <td>3</td>\n      <td>11</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>8</td>\n      <td>3</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25010 rows × 20 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "test_data = test_data[:10000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, sizes):\n",
    "        # sizes is the list of number of neurons in layers of the neural network\n",
    "        self.num_of_layers = len(sizes)\n",
    "        self.layers = sizes\n",
    "        self.weights = [np.ones((y, x)) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        # list of weights or theta matrix for each layer\n",
    "        # print('Weights are ',self.weights)\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.loss = 10000000\n",
    "        # list of (-threshold) for each layer except the input layer\n",
    "\n",
    "    def mbgd(self, training_data, epoch, eta, mini_batch_size, test_data=None):\n",
    "        n = len(training_data)\n",
    "\n",
    "        for i in range(epoch):\n",
    "            # random.shuffle(training_data)\n",
    "            self.loss = 0\n",
    "            start = time()\n",
    "            training_data = shuffle(training_data)\n",
    "            mini_batches = [training_data[k:k + mini_batch_size] for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update(mini_batch, eta)\n",
    "            end = time()\n",
    "            print(\"Epoch {} is completed in time {} and loss is {}\".format(i+1,end - start,self.loss))\n",
    "\n",
    "            if test_data is not None:\n",
    "\n",
    "                r1, r= self.evaluate(test_data)\n",
    "                acc = accuracy_score(r, r1)\n",
    "                print('Accuracy is', acc)\n",
    "\n",
    "    def forward_prop(self, x):\n",
    "        # to return output of network for input layer x\n",
    "        y = x\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            y = sigmoid(np.dot(w, y) + b)\n",
    "        return y\n",
    "\n",
    "    def update(self, mini_batch, eta):\n",
    "        n = len(mini_batch)\n",
    "        grad_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        grad_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        for index, row in mini_batch.iterrows():\n",
    "            x = np.asarray(row[x_col]).reshape(-1,1)\n",
    "            # print(\"X is \", x.T)\n",
    "            y = np.asarray(row[y_col]).reshape(-1,1)\n",
    "            # print(\"Y is \", y.T)\n",
    "            delta_w, delta_b = self.back_prop(x, y)\n",
    "            grad_w = [grad + delta for grad, delta in zip(grad_w, delta_w)]\n",
    "            grad_b = [grad + delta for grad, delta in zip(grad_b, delta_b)]\n",
    "        # print('Updated gradient w is ',grad_w)\n",
    "        self.weights = [w - (eta / n) * grad for w, grad in zip(self.weights, grad_w)]\n",
    "        self.biases = [b - (eta / n) * grad for b, grad in zip(self.biases, grad_b)]\n",
    "\n",
    "        for index, row in mini_batch.iterrows():\n",
    "            x = np.asarray(row[x_col].values).reshape(-1,1)\n",
    "            y = np.array(row[y_col]).reshape(-1,1)\n",
    "            y1 = self.forward_prop(x)\n",
    "            self.loss  += np.sum((y-y1)**2 / (2*n))\n",
    "\n",
    "    def back_prop(self, x, y):\n",
    "        # print(np.shape(x), 'x shape')\n",
    "        # print(np.shape(y), 'y shape')\n",
    "        grad_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        grad_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        zl = []\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zl.append(z)\n",
    "            # print(np.shape(z), 'z shape')\n",
    "            activation = sigmoid(z)\n",
    "            # print(np.shape(activation), ' activation shape')\n",
    "            activations.append(activation)\n",
    "        # print(type(activation[-1]),type(y))\n",
    "        # print(np.shape(activation[-1]), len(y))\n",
    "        delta = (activations[-1] - y) * sigmoid_prime(zl[-1])\n",
    "        grad_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        grad_b[-1] = delta\n",
    "        for i in range(2, self.num_of_layers):\n",
    "            z = zl[-i]\n",
    "            delta = np.dot(self.weights[-i + 1].transpose(), delta) * sigmoid_prime(z)\n",
    "            grad_w[-i] = np.dot(delta, activations[-i - 1].transpose())\n",
    "            grad_b[-i] = delta\n",
    "        return grad_w, grad_b\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        result = []\n",
    "        result2 = []\n",
    "        sum = 0\n",
    "        for index, row in test_data.iterrows():\n",
    "            x = np.asarray(row[x_col].values).reshape(-1,1)\n",
    "            y = np.array(row[y_col]).reshape(-1,1)\n",
    "            y1 = self.forward_prop(x)\n",
    "\n",
    "            result.append(y.argmax())\n",
    "            result2.append(y1.argmax())\n",
    "            # if np.array_equal(y2, y):\n",
    "            #     sum += 1\n",
    "\n",
    "        return result2, result\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, normalize=False, title=None, cmap=plt.cm.Blues):\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = unique_labels(y_true, y_pred)\n",
    "    print('Confusion matrix is >>>>>>>>>>>>>>>')\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 is completed in time 64.3920841217041 and loss is 1129.4999999577394\n",
      "Epoch 2 is completed in time 65.94031715393066 and loss is 1129.4999999577392\n",
      "Epoch 3 is completed in time 66.24550199508667 and loss is 1129.4999999577446\n",
      "Epoch 4 is completed in time 64.2834119796753 and loss is 1129.4999999577428\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [36]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m neural_network \u001B[38;5;241m=\u001B[39m Network(size)\n\u001B[1;32m      3\u001B[0m start \u001B[38;5;241m=\u001B[39m time()\n\u001B[0;32m----> 4\u001B[0m \u001B[43mneural_network\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmbgd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch_no\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m end \u001B[38;5;241m=\u001B[39m time()\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNeural Network Created Successfully !!!\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mTime Taken is \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(end\u001B[38;5;241m-\u001B[39mstart))\n",
      "Input \u001B[0;32mIn [35]\u001B[0m, in \u001B[0;36mNetwork.mbgd\u001B[0;34m(self, training_data, epoch, eta, mini_batch_size, test_data)\u001B[0m\n\u001B[1;32m     21\u001B[0m mini_batches \u001B[38;5;241m=\u001B[39m [training_data[k:k \u001B[38;5;241m+\u001B[39m mini_batch_size] \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, n, mini_batch_size)]\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mini_batch \u001B[38;5;129;01min\u001B[39;00m mini_batches:\n\u001B[0;32m---> 23\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmini_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meta\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m end \u001B[38;5;241m=\u001B[39m time()\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m is completed in time \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m and loss is \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m,end \u001B[38;5;241m-\u001B[39m start,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss))\n",
      "Input \u001B[0;32mIn [35]\u001B[0m, in \u001B[0;36mNetwork.update\u001B[0;34m(self, mini_batch, eta)\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, row \u001B[38;5;129;01min\u001B[39;00m mini_batch\u001B[38;5;241m.\u001B[39miterrows():\n\u001B[1;32m     57\u001B[0m     x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(row[x_col]\u001B[38;5;241m.\u001B[39mvalues)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 58\u001B[0m     y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[43my_col\u001B[49m\u001B[43m]\u001B[49m)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     59\u001B[0m     y1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_prop(x)\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss  \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum((y\u001B[38;5;241m-\u001B[39my1)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39mn))\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:984\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    981\u001B[0m     key \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(key, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mbool\u001B[39m)\n\u001B[1;32m    982\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_values(key)\n\u001B[0;32m--> 984\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_with\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:1024\u001B[0m, in \u001B[0;36mSeries._get_with\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   1021\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miloc[key]\n\u001B[1;32m   1023\u001B[0m \u001B[38;5;66;03m# handle the dup indexing case GH#4246\u001B[39;00m\n\u001B[0;32m-> 1024\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:967\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    964\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    966\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[0;32m--> 967\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1191\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_axis\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1188\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m key\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot index with multidimensional key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1191\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_iterable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1193\u001B[0m \u001B[38;5;66;03m# nested tuple slicing\u001B[39;00m\n\u001B[1;32m   1194\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_nested_tuple(key, labels):\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1132\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_iterable\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1129\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_key(key, axis)\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# A collection of keys\u001B[39;00m\n\u001B[0;32m-> 1132\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_listlike_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1133\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_reindex_with_indexers(\n\u001B[1;32m   1134\u001B[0m     {axis: [keyarr, indexer]}, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_dups\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1135\u001B[0m )\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1327\u001B[0m, in \u001B[0;36m_LocIndexer._get_listlike_indexer\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1324\u001B[0m ax \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis)\n\u001B[1;32m   1325\u001B[0m axis_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis_name(axis)\n\u001B[0;32m-> 1327\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[43max\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1329\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m keyarr, indexer\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:5782\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[0;34m(self, key, axis_name)\u001B[0m\n\u001B[1;32m   5779\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   5780\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[0;32m-> 5782\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5784\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[1;32m   5785\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[1;32m   5786\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:5825\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[0;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[1;32m   5823\u001B[0m \u001B[38;5;66;03m# Count missing values\u001B[39;00m\n\u001B[1;32m   5824\u001B[0m missing_mask \u001B[38;5;241m=\u001B[39m indexer \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 5825\u001B[0m nmissing \u001B[38;5;241m=\u001B[39m \u001B[43mmissing_mask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5827\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m nmissing:\n\u001B[1;32m   5828\u001B[0m \n\u001B[1;32m   5829\u001B[0m     \u001B[38;5;66;03m# TODO: remove special-case; this is just to keep exception\u001B[39;00m\n\u001B[1;32m   5830\u001B[0m     \u001B[38;5;66;03m#  message tests from raising while debugging\u001B[39;00m\n\u001B[1;32m   5831\u001B[0m     use_interval_msg \u001B[38;5;241m=\u001B[39m is_interval_dtype(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   5832\u001B[0m         is_categorical_dtype(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m   5833\u001B[0m         \u001B[38;5;66;03m# \"Index\" has no attribute \"categories\"  [attr-defined]\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5836\u001B[0m         )\n\u001B[1;32m   5837\u001B[0m     )\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:48\u001B[0m, in \u001B[0;36m_sum\u001B[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_sum\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     47\u001B[0m          initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m---> 48\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mumr_sum\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if non_linearity == 'sigmoid' and lr == 'fixed':\n",
    "    neural_network = Network(size)\n",
    "    start = time()\n",
    "    neural_network.mbgd(train_data, epoch_no, 0.1, batch_size)\n",
    "    end = time()\n",
    "    print(\"Neural Network Created Successfully !!!\\nTime Taken is {}\".format(end-start))\n",
    "\n",
    "    # r1, r = neural_network.evaluate(train_data)\n",
    "    # acc = accuracy_score(r, r1)\n",
    "    # print('Training Accuracy ', acc)\n",
    "    print(\"Testing on given test dataset >>>>>>>>>>\")\n",
    "    r12, r2 = neural_network.evaluate(test_data)\n",
    "    acc = accuracy_score(r2, r12)\n",
    "    print('Test accuracy is ', acc)\n",
    "\n",
    "    plot_confusion_matrix(r2, r12, title='Confusion matrix')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}